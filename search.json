[{"path":"https://le-huynh.github.io/chva.extras/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Truc-Ly Le-Huynh Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://le-huynh.github.io/chva.extras/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Truc-Ly Le-Huynh. Author, maintainer, copyright holder. Robert Davis. Contributor, funder. Wendy Novicoff. Funder. Pam DeGuzman. Funder.","code":""},{"path":"https://le-huynh.github.io/chva.extras/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Le-Huynh T (2025). chva.extras: Supplementary Tools Climate Health Research VA. R package version 0.0.0.9000, https://le-huynh.github.io/chva.extras/, https://github.com/le-huynh/chva.extras.","code":"@Manual{,   title = {chva.extras: Supplementary Tools for Climate and Health Research in VA},   author = {Truc-Ly Le-Huynh},   year = {2025},   note = {R package version 0.0.0.9000, https://le-huynh.github.io/chva.extras/},   url = {https://github.com/le-huynh/chva.extras}, }"},{"path":"https://le-huynh.github.io/chva.extras/index.html","id":"chvaextras-","dir":"","previous_headings":"","what":"Supplementary Tools for Climate and Health Research in VA","title":"Supplementary Tools for Climate and Health Research in VA","text":"Supplementary Tools Climate Health Research VA chva.extras collection supplementary functions templates designed support climate health research VA, including tools data manipulation, analysis, visualization, tailored handle large datasets.","code":""},{"path":"https://le-huynh.github.io/chva.extras/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Supplementary Tools for Climate and Health Research in VA","text":"get latest -development features, install development version GitHub:","code":"if(!requireNamespace(\"devtools\", quietly = TRUE)) {  install.packages(\"devtools\") } devtools::install_github(\"le-huynh/chva.extras\")"},{"path":"https://le-huynh.github.io/chva.extras/index.html","id":"functions","dir":"","previous_headings":"Installation","what":"Functions","title":"Supplementary Tools for Climate and Health Research in VA","text":"See Package index full list functions. Convert files Parquet format get_parquet_arrow(): Convert multiple files Parquet format. get_parquet_by_chunk(): Convert file Parquet format chunks. Support handy workflow check_overview(): Provide overview datasets. check_unique_value(): Count unique values specified column. get_dataset(): Get full working datasets named list Dataset R6 objects. recode_values(): Recode values based grouping logic. Compute additional indices used climate health research [updating]","code":""},{"path":"https://le-huynh.github.io/chva.extras/index.html","id":"templates","dir":"","previous_headings":"Installation","what":"Templates","title":"Supplementary Tools for Climate and Health Research in VA","text":"[updating]","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_overview.html","id":null,"dir":"Reference","previous_headings":"","what":"Check dataset overview — check_overview","title":"Check dataset overview — check_overview","text":"Provide overview datasets within specified directory match given pattern. Return summary number rows, columns, flag indicating whether column names across datasets consistent.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_overview.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check dataset overview — check_overview","text":"","code":"check_overview(folder_path, pattern)"},{"path":"https://le-huynh.github.io/chva.extras/reference/check_overview.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check dataset overview — check_overview","text":"folder_path string path directory containing sub-directories input Parquet files. pattern string filter sub-directories input files names.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_overview.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check dataset overview — check_overview","text":"tibble summarizing datasets, columns: name name dataset file. nrow number rows dataset. ncol number columns dataset. matched_column_names logical value indicating whether column names match.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_overview.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check dataset overview — check_overview","text":"","code":"if (FALSE) { # \\dontrun{ overview <- check_overview(folder_path = \"path/to/data_folder\", pattern = \"Facility\") } # }"},{"path":"https://le-huynh.github.io/chva.extras/reference/check_unique_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Check unique values in a column — check_unique_value","title":"Check unique values in a column — check_unique_value","text":"check_unique_value() counts unique values specified column. check_unique_value_overview() takes list outputs check_unique_value() checks consistency unique values within specified column across multiple datasets.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_unique_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check unique values in a column — check_unique_value","text":"","code":"check_unique_value(data, column_to_check)  check_unique_value_overview(data, column_to_check)"},{"path":"https://le-huynh.github.io/chva.extras/reference/check_unique_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check unique values in a column — check_unique_value","text":"data check_unique_value(), data frame element list dataset (output get_dataset()). check_unique_value_overview(), list outputs check_unique_value(). column_to_check column check unique values, using column_name without quotes.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_unique_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check unique values in a column — check_unique_value","text":"check_unique_value(): tibble unique values specified column counts. check_unique_value_overview(): tibble summarizing number unique values element list indicating whether unique values consistent across list elements.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/check_unique_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check unique values in a column — check_unique_value","text":"","code":"list_mtcars <- list(data1 = mtcars, data2 = mtcars, data3 = mtcars)  res_list <- list_mtcars %>%         purrr::map(check_unique_value, column_to_check = cyl)  check_unique_value_overview(res_list, column_to_check = cyl) #> # A tibble: 3 × 3 #>   name  unique_val_number matched_unique_val #>   <chr>             <dbl> <lgl>              #> 1 data1                 3 TRUE               #> 2 data2                 3 TRUE               #> 3 data3                 3 TRUE"},{"path":"https://le-huynh.github.io/chva.extras/reference/delete_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete multiple CSV files — delete_csv","title":"Delete multiple CSV files — delete_csv","text":"function executed converting CSV files Parquet format using get_parquet_arrow() get_parquet_by_chunk(). deletes original CSV files sub-folders specified folder, successfully converted Parquet. function filters sub-folders provided pattern deletes corresponding CSV files.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/delete_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete multiple CSV files — delete_csv","text":"","code":"delete_csv(folder_path, pattern)"},{"path":"https://le-huynh.github.io/chva.extras/reference/delete_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete multiple CSV files — delete_csv","text":"folder_path string path directory containing sub-directories files deleted. pattern string filter sub-directories csv files names.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/delete_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete multiple CSV files — delete_csv","text":"deleted paths (invisibly).","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/delete_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete multiple CSV files — delete_csv","text":"","code":"if (FALSE) { # \\dontrun{ delete_csv(folder_path = \"path/to/data_folder\", pattern = \"Facility\") } # }"},{"path":"https://le-huynh.github.io/chva.extras/reference/get_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Get full working datasets — get_dataset","title":"Get full working datasets — get_dataset","text":"Get full working datasets named list Dataset R6 objects. dataset opened files matching given pattern, names list elements correspond file names.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get full working datasets — get_dataset","text":"","code":"get_dataset(folder_path, pattern)"},{"path":"https://le-huynh.github.io/chva.extras/reference/get_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get full working datasets — get_dataset","text":"folder_path string path directory containing sub-directories input Parquet files. pattern string filter sub-directories input files names.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get full working datasets — get_dataset","text":"named list datasets.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get full working datasets — get_dataset","text":"","code":"if (FALSE) { # \\dontrun{ datasets <- get_dataset(folder_path = \"path/to/data_folder\", pattern = \"Facility\") } # }"},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_arrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert multiple files to Parquet format — get_parquet_arrow","title":"Convert multiple files to Parquet format — get_parquet_arrow","text":"Convert multiple files specified format (e.g., CSV) Parquet format. converted Parquet files saved original location input files, allowing efficient storage retrieval large datasets.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_arrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert multiple files to Parquet format — get_parquet_arrow","text":"","code":"get_parquet_arrow(   folder_path,   pattern,   input_format = \"csv\",   max_rows_per_file = 1e+07 )"},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_arrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert multiple files to Parquet format — get_parquet_arrow","text":"folder_path string path directory containing sub-directories input files. pattern string filter sub-directories input files names. input_format string indicating format input files. Default \"csv\". supported formats listed arrow::open_dataset(). max_rows_per_file Maximum number rows per output Parquet file. Default 1e7 (10 million rows).","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_arrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert multiple files to Parquet format — get_parquet_arrow","text":"Converted Parquet files, saved original location input files.","code":""},{"path":[]},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_arrow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert multiple files to Parquet format — get_parquet_arrow","text":"","code":"if (FALSE) { # \\dontrun{  # Assuming 'folderX' containing 10 sub-folders # (3 folders of city A, 3 folders of city B, and 4 folders of city C) with CSV files, # convert all the data of city C to Parquet format:  get_parquet_arrow(folder_path = \"path/to/folderX\",                   pattern = \"city_C\") } # }"},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_by_chunk.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert file to Parquet format by chunks — get_parquet_by_chunk","title":"Convert file to Parquet format by chunks — get_parquet_by_chunk","text":"Process large file reading chunks writing chunk separate Parquet files.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_by_chunk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert file to Parquet format by chunks — get_parquet_by_chunk","text":"","code":"get_parquet_by_chunk(   input_path,   output_folder,   chunk_no,   nrows_to_read,   column_names,   max_rows_per_file = 1e+07 )"},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_by_chunk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert file to Parquet format by chunks — get_parquet_by_chunk","text":"input_path string path file converted. output_folder string path folder Parquet files saved. chunk_no numeric vector specifying chunks process, 0 first chunk, 1 second, . nrows_to_read numeric value indicating many rows read chunk. column_names character vector column names. max_rows_per_file Maximum number rows per output Parquet file. Default 1e7 (10 million rows).","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_by_chunk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert file to Parquet format by chunks — get_parquet_by_chunk","text":"Converted Parquet files.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_by_chunk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert file to Parquet format by chunks — get_parquet_by_chunk","text":"chunk_no parameter specifies chunks process, 0 first chunk, 1 second, . converted Parquet files named according pattern part{chunk_number}-{}.parquet.","code":""},{"path":[]},{"path":"https://le-huynh.github.io/chva.extras/reference/get_parquet_by_chunk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert file to Parquet format by chunks — get_parquet_by_chunk","text":"","code":"if (FALSE) { # \\dontrun{  # Assuming a large CSV file located at \"path/to/input.csv\", # convert it to Parquet format by processing it in chunks. # The output will be saved in \"path/to/output_folder\".  get_parquet_by_chunk(   input_path = \"path/to/input.csv\",   output_folder = \"path/to/output_folder\",   chunk_no = 0:19,   nrows_to_read = 100000,   column_names = c(\"col1\", \"col2\", \"col3\", \"col4\"),   max_rows_per_file = 50000 ) } # }"},{"path":"https://le-huynh.github.io/chva.extras/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://le-huynh.github.io/chva.extras/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/pipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pipe operator — %>%","text":"","code":"c(1, 2, 3) %>% mean() #> [1] 2"},{"path":"https://le-huynh.github.io/chva.extras/reference/recode_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode values based on grouping logic — recode_values","title":"Recode values based on grouping logic — recode_values","text":"function groups data var1 recodes var2 based specific conditions. var1 one unique var2 value, original value retained. var1 two unique var2 values, known value assigned one matches unknown_category; otherwise, unknown_category assigned. var1 two unique var2 values, unknown_category assigned.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/recode_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode values based on grouping logic — recode_values","text":"","code":"recode_values(data, var1, var2, unknown_category)"},{"path":"https://le-huynh.github.io/chva.extras/reference/recode_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode values based on grouping logic — recode_values","text":"data data frame element list dataset (output get_dataset()). var1 character string specifying grouping variable. var2 character string specifying variable recoded. unknown_category character string specifying ambiguous unknown values var2.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/recode_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode values based on grouping logic — recode_values","text":"data frame var1 recoded var2.","code":""},{"path":"https://le-huynh.github.io/chva.extras/reference/recode_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode values based on grouping logic — recode_values","text":"","code":"df <- data.frame(ID = c(1, 1, 2, 2, 3, 3, 3),                  Status = c(\"Male\", \"Unknown\", \"Female\", \"Female\", \"Male\", \"Female\", \"Unknown\")) recode_values(df, var1 = \"ID\", var2 = \"Status\", unknown_category = \"Unknown\") #> Joining with `by = join_by(ID, Status)` #> Joining with `by = join_by(ID, Status)` #> # A tibble: 3 × 2 #>      ID Status  #>   <dbl> <chr>   #> 1     2 Female  #> 2     1 Male    #> 3     3 Unknown"}]
